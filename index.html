<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>937のBlog - Ciallo～(∠・ω&lt; )⌒★!</title><meta name="author" content="hhh937meow"><meta name="copyright" content="hhh937meow"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="我超，盒！(T^T)">
<meta property="og:type" content="website">
<meta property="og:title" content="937のBlog">
<meta property="og:url" content="https://937miaow.github.io/index.html">
<meta property="og:site_name" content="937のBlog">
<meta property="og:description" content="我超，盒！(T^T)">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://937miaow.github.io/img/avatar.jpg">
<meta property="article:author" content="hhh937meow">
<meta property="article:tag" content="blog">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://937miaow.github.io/img/avatar.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "WebSite",
  "name": "937のBlog",
  "url": "https://937miaow.github.io/"
}</script><link rel="shortcut icon" href="/img/22.png"><link rel="canonical" href="https://937miaow.github.io/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200,"highlightFullpage":true,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '937のBlog',
  isHighlightShrink: false,
  isToc: false,
  pageType: 'home'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">21</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/33.png" alt="Logo"><span class="site-name">937のBlog</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="site-info"><h1 id="site-title">937のBlog</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/937miaow" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:hhh937meow@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts nc" id="recent-posts"><div class="recent-post-items"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/paper/Toolformer-Language-Models-Can-Teach-Themselves-to-Use-Tools/" title="Toolformer: Language Models Can Teach Themselves to Use Tools">Toolformer: Language Models Can Teach Themselves to Use Tools</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-09-01T06:37:35.000Z" title="发表于 2025-09-01 14:37:35">2025-09-01</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-09-01T06:53:12.912Z" title="更新于 2025-09-01 14:53:12">2025-09-01</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">问题 (Problem) 大型语言模型（LLMs）虽然在文本生成和理解上表现出色，但存在一些固有的核心缺陷：  知识过时与幻觉：LLMs的知识被冻结在训练数据的时间点，无法获取最新信息，并且有编造事实（幻觉）的倾向。 缺乏精确计算能力：LLM不擅长进行精确的数学运算，容易在算术问题上犯错。 时间感知能力弱：模型对当前日期和时间没有概念，无法回答与时间流逝相关的问题。 低资源语言处理能力不足：在处理数据稀少的语言时表现不佳。  现有的解决方案通常依赖大量的人工标注来教模型如何使用工具，或者只能在特定任务的设定下使用工具，缺乏通用性。因此，本文旨在解决一个核心问题：如何让语言模型以一种自监督的、通用的方式，学会自己决定何时、如何以及使用何种外部工具来弥补自身缺陷？ 方法 (Method) Toolformer的核心思想是：一个有用的API调用，应该能帮助模型更好地预测未来的文本。基于此，作者提出了一种全新的、自监督的学习范式，让模型“教会自己”使用工具。该方法主要分为三个步骤，如下图2所示：   图例解读：上图以一个问答（QA）工具为例，展示了如何为一个句子 “Pittsburgh ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/paper/AUGMENTING-ZERO-SHOT-DENSE-RETRIEVERS-WITH-PLUG-IN-MIXTURE-OF-MEMORIES/" title="AUGMENTING ZERO-SHOT DENSE RETRIEVERS WITH PLUG-IN MIXTURE-OF-MEMORIES">AUGMENTING ZERO-SHOT DENSE RETRIEVERS WITH PLUG-IN MIXTURE-OF-MEMORIES</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-08-31T11:33:11.000Z" title="发表于 2025-08-31 19:33:11">2025-08-31</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-08-31T12:49:44.363Z" title="更新于 2025-08-31 20:49:44">2025-08-31</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">问题 (Problem) 本文旨在解决稠密检索（Dense Retrieval）模型在**零样本（Zero-Shot）**场景下的泛化能力差的问题。 传统的稠密检索模型在一个大规模的源领域（如网页搜索）上训练后，直接迁移到新的、未见过的目标领域（如生物医药、金融）时，性能会显著下降。虽然通过不断增大语言模型的参数量可以提升泛化性，但这种方式成本高昂且收益递减，在经济上是不可持续的。 因此，核心问题是：如何不通过暴力增加模型参数，而是通过更高效的方式，提升稠密检索模型在不同领域间的零样本迁移和泛化能力？  方法 (Method) 作者提出了一种名为**混合记忆增强（Mixture-Of-Memory Augmentation, MoMA）**的机制，并将其应用于一个基于T5的强大检索器，构建了名为 MoMA-DR 的新系统。 其核心思想是：在对查询（Query）进行编码表示之前，先从一个由**多个不同信息源（语料库）组成的“混合记忆”**中检索出相关的“增强文档”，将这些文档的信息融入查询中，生成一个内容更丰富、意图更明确的“增强后查询表示”，然后再用这个增强后的查询去目标语料库中...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/paper/DynaGRAG-Exploring-the-Topology-of-Information-for-Advancing-Language-Understanding-and-Generation-in-Graph-Retrieval-Augmented-Generation/" title="DynaGRAG | Exploring the Topology of Information for Advancing Language Understanding and Generation in Graph Retrieval-Augmented Generation">DynaGRAG | Exploring the Topology of Information for Advancing Language Understanding and Generation in Graph Retrieval-Augmented Generation</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-08-31T07:19:45.000Z" title="发表于 2025-08-31 15:19:45">2025-08-31</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-08-31T07:29:47.654Z" title="更新于 2025-08-31 15:29:47">2025-08-31</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">问题 (Problem) 大型语言模型 (LLM) 虽然强大，但在处理需要复杂推理、动态演化知识的任务时仍存在局限性。检索增强生成 (RAG) 旨在通过引入外部知识来弥补这一不足，但传统的 RAG 难以有效利用结构化数据。 现有的图增强RAG (Graph RAG) 方法也存在一些问题：  信息粒度损失：一些方法（如微软的GraphRAG）依赖于对图社群进行预先摘要，这种方式牺牲了图的粒度和灵活性。当底层图结构发生变化时，需要重新生成整个索引和摘要，适应性差且计算成本高。 兼容性与焦点局限：另一些方法在与主流LLM架构的兼容性上存在挑战，或者过于关注特定任务（如多跳推理或事实准确性），而忽略了捕捉实体关系的多样性。  因此，核心挑战在于：如何有效捕捉并融合知识图谱中丰富的语义信息和拓扑结构，以增强LLM的语言理解和生成能力，使其能够进行更深层次、更具上下文感知能力的推理。 方法 (Method) 为解决上述问题，该论文提出了一个名为 DynaGRAG (Dynamic Graph Retrieval-Augmented Generation) 的新框架。其核心思想是保留图的原生结...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/paper/GRAG-Graph-Retrieval-Augmented-Generation/" title="GRAG: Graph Retrieval-Augmented Generation">GRAG: Graph Retrieval-Augmented Generation</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-08-30T06:43:49.000Z" title="发表于 2025-08-30 14:43:49">2025-08-30</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-08-30T07:14:30.349Z" title="更新于 2025-08-30 15:14:30">2025-08-30</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">问题 (Problem) 传统的“朴素”检索增强生成（RAG）在处理单个文档时表现良好，但现实世界中的许多数据，如引文网络、社交媒体、知识图谱等，都以相互连接的图（Graph）形式存在。朴素 RAG 的局限性在于：  忽略拓扑信息：它只关注文档的文本内容，忽略了文档之间的连接关系（如引用、链接、关系），而这些连接关系对于深度理解和推理至关重要。 检索单元受限：它以独立的文档作为检索单元，无法检索出一个由多个相关实体及其关系组成的“子图”上下文。   因此，核心问题是：如何让大型语言模型（LLM）在执行 RAG 时，能够有效地利用这种网络化的图结构数据，从而同时理解文本内容和拓扑结构，以生成更准确、更具上下文感知能力的答案？ 这带来了两个核心挑战：  检索挑战：如何从一个大规模的文本图中高效地检索出与问题最相关的文本子图（textual subgraph）？穷举搜索所有可能的子图是一个 NP-hard 问题。 生成挑战：如何将检索到的子图所包含的**联合文本与拓扑信息（joint textual and topological information）**有效地融入到 LLM 中，...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/paper/IMPROVING-LANGUAGE-MODELS-VIA-PLUG-AND-PLAY-RETRIEVAL-FEEDBACK/" title="IMPROVING LANGUAGE MODELS VIA PLUG-AND-PLAY RETRIEVAL FEEDBACK">IMPROVING LANGUAGE MODELS VIA PLUG-AND-PLAY RETRIEVAL FEEDBACK</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-08-29T05:53:03.000Z" title="发表于 2025-08-29 13:53:03">2025-08-29</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-08-29T06:07:10.260Z" title="更新于 2025-08-29 14:07:10">2025-08-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">问题 (Problem) 这篇论文主要解决大型语言模型（LLMs）在实际应用中的几个核心痛点：  内容幻觉与不准确性: 尽管LLMs在多种自然语言处理任务上表现出色，但它们常常会生成不正确或完全捏造（即“幻觉”）的信息，这严重限制了它们在需要高可靠性场景下的应用。 知识局限性: LLMs的知识被固化在其模型参数中，这些知识可能是不完整或过时的，尤其难以覆盖训练语料中的长尾知识。 现有解决方案的缺陷:  人工反馈（如RLHF）: 通过人工标注和强化学习来对齐模型，虽然有效，但极其消耗资源、成本高昂且耗时。 实时性差: 对于已经微调好的模型，很难在推理过程中实时接收反馈并进行即时纠错。    因此，论文的核心研究问题是：我们能否在不进行昂贵微调的前提下，设计一个即插即用的自动化流程，利用外部知识库对LLM的生成内容进行反馈和修正，从而提升其准确性？  方法 (Method) 论文提出了一种名为 REFEED (REtrieval FEEDback) 的新型工作流，其核心思想是“先生成，再检索，后优化”，将检索作为一种反馈机制而非传统的输入增强。 基础工作流 (Basic Pipeli...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/paper/Atlas-Few-shot-Learning-with-Retrieval-Augmented-Language-Models/" title="Atlas: Few-shot Learning with Retrieval Augmented Language Models">Atlas: Few-shot Learning with Retrieval Augmented Language Models</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-08-28T14:31:28.000Z" title="发表于 2025-08-28 22:31:28">2025-08-28</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-08-28T17:09:09.592Z" title="更新于 2025-08-29 01:09:09">2025-08-29</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">问题 (Problem) 传统的大型语言模型（LLMs）在少样本学习（few-shot learning）上表现出色，但这通常依赖于巨大的参数量来存储世界知识。这引发了一个核心问题：强大的少样本学习能力是否必须与庞大的模型参数（即内置记忆）绑定？ 这篇论文旨在探讨是否可以将模型的“记忆”（知识存储）与“推理”（泛化能力）解耦。作者假设，通过将知识存储外包给一个外部的、可检索的知识库，模型可以将更多参数用于学习推理和泛化能力，从而在拥有较少参数的情况下，在知识密集型任务（如问答、事实核查）上实现卓越的少样本学习性能。 本文的目标是设计并训练一个精心构建的检索增强语言模型——ATLAS，验证其在知识密集型任务上，仅用少量样本就能超越巨大参数量模型的潜力。  方法 (Method) ATLAS 遵循一个统一的“文本到文本”（text-to-text）框架，其中所有任务都被建模为：输入一个文本查询（query），生成一个文本输出（output）。其核心是一个由**检索器（Retriever）和语言模型（Language Model）**组成的双模块架构。 模型架构 (Architectu...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/paper/REPLUG-Retrieval-Augmented-Black-Box-Language-Models/" title="REPLUG: Retrieval-Augmented Black-Box Language Models">REPLUG: Retrieval-Augmented Black-Box Language Models</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-08-27T12:56:55.000Z" title="发表于 2025-08-27 20:56:55">2025-08-27</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-08-27T13:10:07.555Z" title="更新于 2025-08-27 21:10:07">2025-08-27</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">问题 (Problem) 大型语言模型（LLMs）如GPT-3虽然强大，但存在两个核心问题：  知识局限性：模型参数中存储的知识是静态的，无法实时更新，且对于长尾知识（rare knowledge）的覆盖不全，容易产生事实性错误或“幻觉”。 黑盒特性：当前最先进的LLMs（通常 &gt;100B 参数）往往通过API提供服务，用户无法访问模型的内部参数、梯度或进行微调。这使得传统的、需要“白盒”访问权限的检索增强方法（如RETRO、Atlas）无法适用。  因此，本文的核心问题是：如何在只能“黑盒”访问（即只能输入文本、获取输出）的前提下，通过外部知识库对大型语言模型进行有效的检索增强，以提升其性能并减少幻觉？ 方法 (Method) 作者提出了 REPLUG (Retrieve and Plug) 框架，它将语言模型视为一个不可更改的黑盒，并将一个可调优的检索器作为插件来增强它。 REPLUG 推理过程 REPLUG的推理过程分为两步：文档检索 和 输入重构与集成。  REPLUG 推理流程图（论文Figure 2）   文档检索 (Document Retrieval)  给...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/paper/Zero-Shot-Dense-Retrieval-with-Embeddings-from-Relevance-Feedback/" title="Zero-Shot Dense Retrieval with Embeddings from Relevance Feedback">Zero-Shot Dense Retrieval with Embeddings from Relevance Feedback</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-08-24T12:46:13.000Z" title="发表于 2025-08-24 20:46:13">2025-08-24</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-08-24T12:57:17.707Z" title="更新于 2025-08-24 20:57:17">2025-08-24</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">问题 (Problem) 在信息检索领域，密集检索（Dense Retrieval）系统通常需要大量的标注数据（即“查询-相关文档”对）进行训练才能达到良好效果。但在许多场景下，这种标注数据是稀缺或不存在的。因此，如何在没有标注数据的情况下（即零样本 Zero-Shot 场景）构建高效的密集检索系统，是一个核心挑战。 现有的SOTA（State-of-the-art）方法，如HyDE，尝试使用大语言模型（LLM）来解决这个问题。它的思路是：针对一个用户查询，让LLM生成一篇“假想的”（hypothetical）相关文档，然后用这篇假想文档的向量去寻找语料库中内容最相似的真实文档。 然而，这种依赖LLM生成假想文档的方法存在三个主要缺陷：  知识局限性：该方法严重依赖LLM自身的参数化知识。如果查询涉及特定或专有领域（如公司内部文档），LLM可能无法生成高质量、有事实依据的假想文档。 效率低下：对于每个查询，LLM都需要生成一篇完整的文档（包含大量token），这个生成过程非常耗时，导致检索延迟很高。 内容不可靠：即使给LLM提供一些参考文档作为上下文，它在生成内容时也可能出现幻觉...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/paper/Gecko-Versatile-Text-Embeddings-Distilled-from-Large-Language-Models/" title="Gecko: Versatile Text Embeddings Distilled from Large Language Models">Gecko: Versatile Text Embeddings Distilled from Large Language Models</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-08-21T11:13:57.000Z" title="发表于 2025-08-21 19:13:57">2025-08-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-08-24T12:47:06.670Z" title="更新于 2025-08-24 20:47:06">2025-08-24</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">问题 (Problem) 论文旨在解决当前文本嵌入模型领域的核心挑战：如何创建一个既紧凑又通用的文本嵌入模型。 现有方法存在以下痛点：  通用性差：许多模型在特定任务（如语义相似度）上表现优异，但在跨任务、跨领域（如信息检索、分类、聚类等）的泛化能力上表现不佳。 数据依赖严重：要构建一个覆盖多领域、多任务的通用模型，通常需要海量的、高质量的人工标注数据。这个过程不仅成本高昂、耗时费力，而且难以覆盖所有场景。 模型效率问题：为了追求高性能，模型往往变得越来越大（例如参数量超过70亿），嵌入维度也越来越高（例如超过4000维），这给实际部署和应用带来了巨大的计算和存储开销。  因此，本文的核心问题是：我们能在多大程度上直接利用大型语言模型（LLM）中蕴含的丰富世界知识，来蒸馏出一个紧凑、高效且在多种任务上都表现出色的通用文本嵌入模型？ 方法 (Method) 本文提出了 Gecko，一个通过两步式LLM知识蒸馏流程训练得到的文本嵌入模型。其核心是创建了一个名为 FRet (Few-shot Prompted Retrieval dataset) 的高质量合成数据集。  FRet：两步...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/paper/Multilingual-E5-Text-Embeddings/" title="Multilingual E5 Text Embeddings">Multilingual E5 Text Embeddings</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-08-21T06:24:58.000Z" title="发表于 2025-08-21 14:24:58">2025-08-21</time><span class="article-meta-separator">|</span><i class="fas fa-history"></i><span class="article-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-08-21T06:29:14.311Z" title="更新于 2025-08-21 14:29:14">2025-08-21</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/paper/">paper</a></span></div><div class="content">核心问题 (Problem) 现有的文本嵌入（Text Embedding）模型大多只在英文语料上进行训练，这极大地限制了它们在多语言场景下的应用。为了解决这一问题，微软的研究人员开发了一系列名为mE5（multilingual E5）的开源多语言文本嵌入模型，旨在提供在多种语言上都表现出色的高质量文本表示能力。  核心方法 (Method) 该论文的核心方法沿用了其英文版E5模型的两阶段训练流程：弱监督对比学习预训练 + 监督微调。此外，还引入了一个创新的**指令微调（instruction-tuned）**版本。 模型架构与初始化 研究人员发布了三种不同规模的模型，以平衡效果和效率：  mE5-small: 基于multilingual-MiniLM初始化。 mE5-base: 基于xlm-roberta-base初始化。 mE5-large: 基于xlm-roberta-large初始化。  第一阶段：弱监督对比学习预训练 (Weakly-supervised Contrastive Pre-training) 此阶段的目标是让模型从海量无标注或弱标注数据中学习通用的多语言...</div></div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/#content-inner">2</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">hhh937meow</div><div class="author-info-description">Ciallo～(∠・ω< )⌒★!</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">21</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/937miaow"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/937miaow" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:hhh937meow@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Ciallo～(∠・ω< )⌒★!</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/paper/Toolformer-Language-Models-Can-Teach-Themselves-to-Use-Tools/" title="Toolformer: Language Models Can Teach Themselves to Use Tools">Toolformer: Language Models Can Teach Themselves to Use Tools</a><time datetime="2025-09-01T06:37:35.000Z" title="发表于 2025-09-01 14:37:35">2025-09-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/paper/AUGMENTING-ZERO-SHOT-DENSE-RETRIEVERS-WITH-PLUG-IN-MIXTURE-OF-MEMORIES/" title="AUGMENTING ZERO-SHOT DENSE RETRIEVERS WITH PLUG-IN MIXTURE-OF-MEMORIES">AUGMENTING ZERO-SHOT DENSE RETRIEVERS WITH PLUG-IN MIXTURE-OF-MEMORIES</a><time datetime="2025-08-31T11:33:11.000Z" title="发表于 2025-08-31 19:33:11">2025-08-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/paper/DynaGRAG-Exploring-the-Topology-of-Information-for-Advancing-Language-Understanding-and-Generation-in-Graph-Retrieval-Augmented-Generation/" title="DynaGRAG | Exploring the Topology of Information for Advancing Language Understanding and Generation in Graph Retrieval-Augmented Generation">DynaGRAG | Exploring the Topology of Information for Advancing Language Understanding and Generation in Graph Retrieval-Augmented Generation</a><time datetime="2025-08-31T07:19:45.000Z" title="发表于 2025-08-31 15:19:45">2025-08-31</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/paper/GRAG-Graph-Retrieval-Augmented-Generation/" title="GRAG: Graph Retrieval-Augmented Generation">GRAG: Graph Retrieval-Augmented Generation</a><time datetime="2025-08-30T06:43:49.000Z" title="发表于 2025-08-30 14:43:49">2025-08-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/paper/IMPROVING-LANGUAGE-MODELS-VIA-PLUG-AND-PLAY-RETRIEVAL-FEEDBACK/" title="IMPROVING LANGUAGE MODELS VIA PLUG-AND-PLAY RETRIEVAL FEEDBACK">IMPROVING LANGUAGE MODELS VIA PLUG-AND-PLAY RETRIEVAL FEEDBACK</a><time datetime="2025-08-29T05:53:03.000Z" title="发表于 2025-08-29 13:53:03">2025-08-29</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>分类</span>
            
          </div>
          <ul class="card-category-list expandBtn" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/DataStru-Algo/"><span class="card-category-list-name">DataStru&Algo</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/paper/"><span class="card-category-list-name">paper</span><span class="card-category-list-count">16</span></a></li>
          </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/paper/" style="font-size: 1.45em; color: rgb(61, 98, 61);">paper</a><a href="/tags/Retrieval/" style="font-size: 1.4em; color: rgb(141, 86, 137);">Retrieval</a><a href="/tags/Neural-IR/" style="font-size: 1.15em; color: rgb(131, 171, 88);">Neural IR</a><a href="/tags/Embedding/" style="font-size: 1.2em; color: rgb(135, 119, 137);">Embedding</a><a href="/tags/LLM/" style="font-size: 1.35em; color: rgb(89, 50, 50);">LLM</a><a href="/tags/Dense-Retrieval/" style="font-size: 1.3em; color: rgb(51, 67, 50);">Dense Retrieval</a><a href="/tags/zero-shot/" style="font-size: 1.25em; color: rgb(50, 50, 58);">zero-shot</a><a href="/tags/supervised/" style="font-size: 1.15em; color: rgb(70, 50, 177);">supervised</a><a href="/tags/Embeddings/" style="font-size: 1.15em; color: rgb(69, 50, 64);">Embeddings</a><a href="/tags/Data-Structure/" style="font-size: 1.2em; color: rgb(195, 159, 50);">Data Structure</a><a href="/tags/Algorithm/" style="font-size: 1.2em; color: rgb(146, 59, 188);">Algorithm</a><a href="/tags/SCNU-Turing-Discussion/" style="font-size: 1.2em; color: rgb(50, 123, 162);">SCNU Turing Discussion</a><a href="/tags/Maximum-Flow/" style="font-size: 1.15em; color: rgb(50, 55, 74);">Maximum Flow</a><a href="/tags/Graph/" style="font-size: 1.15em; color: rgb(50, 197, 76);">Graph</a><a href="/tags/unsupervised/" style="font-size: 1.15em; color: rgb(108, 50, 50);">unsupervised</a><a href="/tags/BST/" style="font-size: 1.15em; color: rgb(133, 110, 114);">BST</a><a href="/tags/RBT/" style="font-size: 1.15em; color: rgb(134, 50, 79);">RBT</a><a href="/tags/RAG/" style="font-size: 1.2em; color: rgb(50, 132, 50);">RAG</a><a href="/tags/NLP/" style="font-size: 1.15em; color: rgb(86, 171, 99);">NLP</a><a href="/tags/few-shot/" style="font-size: 1.15em; color: rgb(198, 50, 140);">few-shot</a><a href="/tags/GRAG/" style="font-size: 1.2em; color: rgb(50, 50, 55);">GRAG</a></div></div><div class="card-widget card-archives">
    <div class="item-headline">
      <i class="fas fa-archive"></i>
      <span>归档</span>
      
    </div>
  
    <ul class="card-archive-list">
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/09/">
            <span class="card-archive-list-date">
              九月 2025
            </span>
            <span class="card-archive-list-count">1</span>
          </a>
        </li>
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2025/08/">
            <span class="card-archive-list-date">
              八月 2025
            </span>
            <span class="card-archive-list-count">15</span>
          </a>
        </li>
      
        <li class="card-archive-list-item">
          <a class="card-archive-list-link" href="/archives/2024/05/">
            <span class="card-archive-list-date">
              五月 2024
            </span>
            <span class="card-archive-list-count">2</span>
          </a>
        </li>
      
    </ul>
  </div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站信息</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">18</div></div><div class="webinfo-item"><div class="item-name">运行时间 :</div><div class="item-count" id="runtimeshow" data-publishDate="2025-08-09T16:00:00.000Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">本站总浏览量 :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-09-01T06:54:07.350Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By hhh937meow</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div><div class="footer_custom_text">Hi, welcome to my <a href="https://937miaow.github.io">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><div class="js-pjax"><script>window.typedJSFn = {
  init: str => {
    window.typed = new Typed('#subtitle', Object.assign({
      strings: str,
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50,
    }, null))
  },
  run: subtitleType => {
    if (true) {
      if (typeof Typed === 'function') {
        subtitleType()
      } else {
        btf.getScript('https://cdn.jsdelivr.net/npm/typed.js/dist/typed.umd.min.js').then(subtitleType)
      }
    } else {
      subtitleType()
    }
  },
  processSubtitle: (content, extraContents = []) => {
    if (true) {
      const sub = ["愿此行终抵群星","Ciallo～(∠・ω< )⌒★!","爱丽丝错了，爱丽丝不该在网上口嗨的","私のオナニーを見てください","芽衣姐，窝不想似","不 会 还 有 人 盯 着 subtitle 吧 ("].slice()

      if (extraContents.length > 0) {
        sub.unshift(...extraContents)
      }

      if (typeof content === 'string') {
        sub.unshift(content)
      } else if (Array.isArray(content)) {
        sub.unshift(...content)
      }

      sub.length > 0 && typedJSFn.init(sub)
    } else {
      document.getElementById('subtitle').textContent = typeof content === 'string' ? content :
        (Array.isArray(content) && content.length > 0 ? content[0] : '')
    }
  }
}
btf.addGlobalFn('pjaxSendOnce', () => { typed.destroy() }, 'typedDestroy')
</script><script>function subtitleType () {
  typedJSFn.processSubtitle(["愿此行终抵群星","Ciallo～(∠・ω< )⌒★!","爱丽丝错了，爱丽丝不该在网上口嗨的","私のオナニーを見てください","芽衣姐，窝不想似","不 会 还 有 人 盯 着 subtitle 吧 ("])
}
typedJSFn.run(subtitleType)</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>